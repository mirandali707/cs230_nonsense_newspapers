{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Grab LCCNs for different newspaper titles at this link: [https://chroniclingamerica.loc.gov/newspapers.txt](https://chroniclingamerica.loc.gov/newspapers.txt). This LCCN is essentially a unique identifier for each newspaper title. For your project, I'd recommend sticking to titles published after 1900, as headlines didn't really become prominent on the front pages of newspaper pages until the turn of the century.\n",
    "\n",
    "2. Once you have the LCCN, you can access all of the different issues for that specific newspaper title in JSON format by going to: [https://chroniclingamerica.loc.gov/lccn/sn86069873.json](https://chroniclingamerica.loc.gov/lccn/sn86069873.json) (here, I'm using The Bourbon News from Kentucky with the LCCN \"sn86069873\" as an example).\n",
    "\n",
    "3. In the JSON, you'll find a URL to a JSON file containing the page-level data for each issue. For example, see: [https://chroniclingamerica.loc.gov/lccn/sn86069873/1897-01-08/ed-1.json](https://chroniclingamerica.loc.gov/lccn/sn86069873/1897-01-08/ed-1.json). If you then adjust this URL by appending \"/seq-1.jp2\", you'll then be able to download the front page (for example, [https://chroniclingamerica.loc.gov/lccn/sn86069873/1897-01-08/ed-1/seq-1.jp2](https://chroniclingamerica.loc.gov/lccn/sn86069873/1897-01-08/ed-1/seq-1.jp2)). The number of front pages is then just the number of newspaper issues listed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getting LCCNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab LCCNs for different newspaper titles at this link: https://chroniclingamerica.loc.gov/newspapers.txt. This LCCN is essentially a unique identifier for each newspaper title."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing / data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "newspapers_df = pd.read_csv('https://chroniclingamerica.loc.gov/newspapers.txt', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "newspapers_df.columns = [col_name.strip() for col_name in newspapers_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month(date_string):\n",
    "    \"\"\"\n",
    "    given date string, returns month and index where numerical date starts (`date_index`)\n",
    "    \"\"\"\n",
    "    date_index = re.search(r\"\\d\", date_string).start()\n",
    "    month = date_string[:date_index].strip('. ')\n",
    "    return month, date_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_datetime(date_string):\n",
    "    \"\"\"\n",
    "    converts date_string (from either 'First Issue Date' or 'Last Issue Date' in LOC newspaper dataset) to time.struct_time object\n",
    "    \"\"\"\n",
    "    date_string = date_string.strip()\n",
    "    month, date_index = get_month(date_string)\n",
    "    if len(month) == 3 and month != 'May':\n",
    "        return time.strptime(date_string, '%b. %d, %Y')\n",
    "    if month == 'Sept':\n",
    "        date_string = 'September ' + date_string[date_index:]\n",
    "    return time.strptime(date_string, '%B %d, %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "newspapers_df['First Issue Date'] = newspapers_df['First Issue Date'].map(convert_datetime)\n",
    "newspapers_df['Last Issue Date'] = newspapers_df['Last Issue Date'].map(convert_datetime)\n",
    "newspapers_df['LCCN'] = newspapers_df['LCCN'].map(lambda lccn : lccn.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newspapers_df.to_pickle(\"newspapers_df.pkl\")\n",
    "newspapers_df = pd.read_pickle(\"newspapers_df.pkl\") # UNCOMMENT TO UNPICKLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Persistent Link</th>\n",
       "      <th>State</th>\n",
       "      <th>Title</th>\n",
       "      <th>LCCN</th>\n",
       "      <th>OCLC</th>\n",
       "      <th>ISSN</th>\n",
       "      <th>No. of Issues</th>\n",
       "      <th>First Issue Date</th>\n",
       "      <th>Last Issue Date</th>\n",
       "      <th>More Info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn8607...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>The age-herald. [volume] (Birmingham, Ala.) 1...</td>\n",
       "      <td>sn86072192</td>\n",
       "      <td>14948274</td>\n",
       "      <td>2692-4099</td>\n",
       "      <td>1630</td>\n",
       "      <td>(1897, 8, 1, 0, 0, 0, 6, 213, -1)</td>\n",
       "      <td>(1902, 5, 20, 0, 0, 0, 1, 140, -1)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn8402...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama state intelligencer. [volume] (Tuscal...</td>\n",
       "      <td>sn84021903</td>\n",
       "      <td>2683862</td>\n",
       "      <td>2574-4089</td>\n",
       "      <td>50</td>\n",
       "      <td>(1831, 1, 1, 0, 0, 0, 5, 1, -1)</td>\n",
       "      <td>(1831, 12, 24, 0, 0, 0, 5, 358, -1)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn8402...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Birmingham age-herald. [volume] (Birmingham, ...</td>\n",
       "      <td>sn84020639</td>\n",
       "      <td>4066065</td>\n",
       "      <td>2692-4226</td>\n",
       "      <td>423</td>\n",
       "      <td>(1894, 7, 1, 0, 0, 0, 6, 182, -1)</td>\n",
       "      <td>(1895, 10, 3, 0, 0, 0, 3, 276, -1)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Persistent Link      State  \\\n",
       "0  https://chroniclingamerica.loc.gov/lccn/sn8607...   Alabama    \n",
       "1  https://chroniclingamerica.loc.gov/lccn/sn8402...   Alabama    \n",
       "2  https://chroniclingamerica.loc.gov/lccn/sn8402...   Alabama    \n",
       "\n",
       "                                               Title        LCCN      OCLC  \\\n",
       "0   The age-herald. [volume] (Birmingham, Ala.) 1...  sn86072192  14948274   \n",
       "1   Alabama state intelligencer. [volume] (Tuscal...  sn84021903   2683862   \n",
       "2   Birmingham age-herald. [volume] (Birmingham, ...  sn84020639   4066065   \n",
       "\n",
       "          ISSN  No. of Issues                   First Issue Date  \\\n",
       "0   2692-4099            1630  (1897, 8, 1, 0, 0, 0, 6, 213, -1)   \n",
       "1   2574-4089              50    (1831, 1, 1, 0, 0, 0, 5, 1, -1)   \n",
       "2   2692-4226             423  (1894, 7, 1, 0, 0, 0, 6, 182, -1)   \n",
       "\n",
       "                       Last Issue Date More Info  \n",
       "0   (1902, 5, 20, 0, 0, 0, 1, 140, -1)            \n",
       "1  (1831, 12, 24, 0, 0, 0, 5, 358, -1)            \n",
       "2   (1895, 10, 3, 0, 0, 0, 3, 276, -1)            "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newspapers_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filtering\n",
    "For your project, I'd recommend sticking to titles published after 1900, as headlines didn't really become prominent on the front pages of newspaper pages until the turn of the century."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2443029 newspaper issues and 3327 LCCNs total\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {sum(newspapers_df['No. of Issues'])} newspaper issues and {len(newspapers_df['LCCN'])} LCCNs total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1114757 issues from publications started before but active during Mon Jan  1 00:00:00 1900\n"
     ]
    }
   ],
   "source": [
    "# start_before = newspapers_df['First Issue Date'] < START_DATE\n",
    "# end_after = newspapers_df['Last Issue Date'] > START_DATE\n",
    "# turn_of_century_papers = newspapers_df[start_before & end_after]\n",
    "# print(f\"There are {sum(turn_of_century_papers['No. of Issues'])} issues from publications started before but active during {time.asctime(START_DATE)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lccns(start_date_str, newspapers_df):\n",
    "    \"\"\"\n",
    "    start_date_str should be a string of the format 'Month Date Year' e.g. 'January 1 1950', representing the publication start date\n",
    "    prints the number of LCCNs and the number of issues total\n",
    "    returns a list of LCCNs\n",
    "    \"\"\"\n",
    "    start_date = time.strptime(start_date_str, '%B %d %Y')\n",
    "    filtered_newspapers = newspapers_df[newspapers_df['First Issue Date'] >= start_date]\n",
    "    filtered_LCCNs = filtered_newspapers['LCCN']\n",
    "    \n",
    "    print(f\"There are {sum(filtered_newspapers['No. of Issues'])} issues and {len(filtered_LCCNs)} LCCNs from publications started after {start_date_str}\")\n",
    "    \n",
    "    return list(filtered_LCCNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 683352 issues and 1123 LCCNs from publications started after January 1 1900\n"
     ]
    }
   ],
   "source": [
    "lccn_1900_683352 = get_lccns('January 1 1900', newspapers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1003 issues and 8 LCCNs from publications started after January 1 1959\n"
     ]
    }
   ],
   "source": [
    "lccn_1959_1003 = get_lccns('January 1 1959', newspapers_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# writing list of front page image links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the LCCN, you can access all of the different issues for that specific newspaper title in JSON format by going to: https://chroniclingamerica.loc.gov/lccn/sn86069873.json (here, I'm using The Bourbon News from Kentucky with the LCCN \"sn86069873\" as an example).\n",
    "\n",
    "In the JSON, you'll find a URL to a JSON file containing the page-level data for each issue. For example, see: https://chroniclingamerica.loc.gov/lccn/sn86069873/1897-01-08/ed-1.json. If you then adjust this URL by appending \"/seq-1.jp2\", you'll then be able to download the front page (for example, https://chroniclingamerica.loc.gov/lccn/sn86069873/1897-01-08/ed-1/seq-1.jp2). The number of front pages is then just the number of newspaper issues listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import sys\n",
    "from progressbar import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_image_links(lccns, out_filename, error_filename, one_page_per_lccn=False):\n",
    "    \"\"\"\n",
    "    writes links to jp2 images for all front pages published by outlets with lccns in `lccns` to out_filename; writes errors to error_filename.\n",
    "    if one_page_per_lccn == True, only gets one front page, that of MOST RECENT issue, per publisher (default is to get all front pages from all issues)\n",
    "    \"\"\"\n",
    "    front_pages = []\n",
    "    failed_lccns = []\n",
    "    pbar = ProgressBar()\n",
    "\n",
    "    with open(out_filename, 'a') as out_file, open(error_filename, 'a') as error_file:\n",
    "        for lccn in pbar(lccns):\n",
    "            try:\n",
    "                paper = requests.get('https://chroniclingamerica.loc.gov/lccn/' + lccn + '.json').json()\n",
    "                if one_page_per_lccn:\n",
    "                    url = paper['issues'][-1]['url'] # get url for most recent issue\n",
    "                    out_file.write(url[:-5] + '/seq-1.jp2\\n') # append link to first page to out_file\n",
    "                else:\n",
    "                    urls = [issue['url'] for issue in paper['issues']] # get urls for all issues\n",
    "                    out_file.writelines([issue_url[:-5] + '/seq-1.jp2\\n' for issue_url in urls]) # append all first page links to out_file\n",
    "            except:\n",
    "                e = sys.exc_info()\n",
    "                error_file.write(f\"LCCN {lccn} failed with error {str(e)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "write_image_links(lccn_1959_1003, 'links_1959_unique_8.txt', 'errors_1959_unique_8.txt', one_page_per_lccn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "write_image_links(lccn_1959_1003, 'links_1959_1003.txt', 'errors_1959_1003.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "write_image_links(lccn_1900_683352, 'links_1900_unique_1123.txt', 'errors_1900_unique_1123.txt', one_page_per_lccn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getting images from links into specified directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEPRECATED // OUT OF DATE**\n",
    "see `get_images.py` instead :^)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ brew tap hhatto/pgmagick\n",
    "# $ brew install pgmagick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_name(image_link):\n",
    "    \"\"\"\n",
    "    given link to jp2 image (e.g. 'https://chroniclingamerica.loc.gov/lccn/sn83045298/1963-12-20/ed-1/seq-1.jp2'),\n",
    "    returns name of image by joining all parts of the url following and including the lccn value (e.g. sn83045298) with underscores\n",
    "    \"\"\"\n",
    "    return ('_'.join(image_link.split('/')[4:])).strip()[:-1] + 'g'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sn83045298_1963-12-20_ed-1_seq-1.jpg'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_image_name('https://chroniclingamerica.loc.gov/lccn/sn83045298/1963-12-20/ed-1/seq-1.jp2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_jp2_images(links_filename, error_filename, out_dir):\n",
    "    \"\"\"\n",
    "    writes all .jp2 images with links in links_filename as into out_dir; writes errors into error_filename\n",
    "    \"\"\"\n",
    "    with open(links_filename, 'r') as links, open(error_filename, 'a') as error_file:\n",
    "        for image_link in links:\n",
    "            try:\n",
    "                image_name = get_image_name(image_link)\n",
    "                if not os.path.isfile(out_dir + '/' + image_name):\n",
    "                    # pulls image\n",
    "                    r = requests.get(image_link, stream=True)\n",
    "                    # makes sure the request passed:\n",
    "                    if r.status_code == 200:\n",
    "                        with open(out_dir + '/' + image_name, 'wb') as f:\n",
    "                            f.write(r.content)\n",
    "            except:\n",
    "                e = sys.exc_info()\n",
    "                error_file.write(f\"Could not get image {image_link}; failed with error {str(e)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jp2_images('links_1959_unique_8.txt', 'error_1959_unique_8.txt', 'testjpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('testjpg/sn83045298_1963-12-20_ed-1_seq-1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jp2s_to_pngs(jp2s_dir):\n",
    "    command = f\"opj_decompress -ImgDir {jp2s_dir} -OutFor png\" #TODO: TEST THIS ON AWS\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_resize(png_file, dim=1024):\n",
    "    # resize to maintain aspect ratio\n",
    "    img = Image.open(png_file)\n",
    "    wpercent = (dim / float(img.size[0]))\n",
    "    hsize = int((float(img.size[1]) * float(wpercent)))\n",
    "    img = img.resize((dim, hsize), PIL.Image.ANTIALIAS)\n",
    "    \n",
    "    # crop image\n",
    "    (left, upper, right, lower) = (0, 0, dim, dim)\n",
    "    img = img.crop((left, upper, right, lower))\n",
    "\n",
    "    img.save('resized_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_file = 'blabla.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blabla'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "png_file[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
